# Gu√≠a: Migraci√≥n a Transcripci√≥n y Procesamiento Privado de Audio

## Objetivo del Proyecto

Migrar una aplicaci√≥n web que actualmente:
1. **Graba audio** ‚Üí Transcribe con Whisper API (OpenAI)
2. **Procesa texto** ‚Üí Extrae datos con OpenAI API (nombre, apellidos, fecha nacimiento, etc.)
3. **Almacena datos** ‚Üí Env√≠a a Google Sheets

**Meta**: Eliminar dependencias externas para proteger la privacidad de datos sensibles, manteniendo la misma funcionalidad.

---

## Arquitectura Actual vs Nueva

### üî¥ **Arquitectura Actual (Problem√°tica)**
```
Audio ‚Üí Whisper API (OpenAI) ‚Üí Texto ‚Üí OpenAI API ‚Üí Datos ‚Üí Google Sheets
       [‚ùå Privacidad]              [‚ùå Privacidad]
```

### üü¢ **Arquitectura Nueva (Privada)**
```
Audio ‚Üí Whisper Local ‚Üí Texto ‚Üí Extracci√≥n Local ‚Üí Datos ‚Üí Google Sheets
       [‚úÖ 100% Local]         [‚úÖ 100% Local]
```

---

## Implementaci√≥n T√©cnica

### 1. **Transcripci√≥n de Audio (Reemplazar Whisper API)**

#### Opci√≥n A: Transformers.js + Whisper (Recomendada)
```javascript
import { pipeline } from '@xenova/transformers';

// Configurar transcriptor una sola vez
const transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-base', {
    quantized: true,  // Reduce tama√±o del modelo
    device: 'webgpu', // Usa GPU si est√° disponible
    language: 'es'    // Espa√±ol
});

// Funci√≥n de transcripci√≥n
async function transcribeAudio(audioBlob) {
    try {
        const result = await transcriber(audioBlob);
        return result.text;
    } catch (error) {
        console.error('Error en transcripci√≥n:', error);
        return null;
    }
}
```

#### Opci√≥n B: Web Speech API (M√°s r√°pida, menos precisa)
```javascript
function setupSpeechRecognition() {
    const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    
    recognition.continuous = true;
    recognition.interimResults = false;
    recognition.lang = 'es-ES';
    
    recognition.onresult = function(event) {
        const transcript = event.results[0][0].transcript;
        processExtractedText(transcript);
    };
    
    recognition.onerror = function(event) {
        console.error('Error de reconocimiento:', event.error);
    };
    
    return recognition;
}
```

### 2. **Extracci√≥n de Datos (Reemplazar OpenAI API)**

#### Opci√≥n A: Patrones Regex (M√°s eficiente para datos estructurados)
```javascript
function extractPersonalData(text) {
    const patterns = {
        // Nombres
        nombre: /(?:me llamo|soy|mi nombre es)\s+([A-Z√Å√â√ç√ì√ö√ú][a-z√°√©√≠√≥√∫√º]+(?:\s+[A-Z√Å√â√ç√ì√ö√ú][a-z√°√©√≠√≥√∫√º]+)*)/gi,
        
        // Apellidos
        apellidos: /apellidos?\s+(?:son?\s+)?([A-Z√Å√â√ç√ì√ö√ú][a-z√°√©√≠√≥√∫√º]+(?:\s+[A-Z√Å√â√ç√ì√ö√ú][a-z√°√©√≠√≥√∫√º]+)*)/gi,
        
        // Fecha de nacimiento (m√∫ltiples formatos)
        fechaNacimiento: /(?:nac√≠|nacido|fecha de nacimiento|cumplea√±os).*?(\d{1,2}[\s\/\-](?:de\s+)?\w+[\s\/\-]\d{4}|\d{1,2}[\s\/\-]\d{1,2}[\s\/\-]\d{4})/gi,
        
        // Tel√©fono
        telefono: /(?:tel√©fono|m√≥vil|celular).*?(\+?\d{1,3}[\s\-]?\d{3}[\s\-]?\d{3}[\s\-]?\d{3})/gi,
        
        // Email
        email: /(?:email|correo).*?([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})/gi,
        
        // DNI/NIE
        dni: /(?:dni|nie|documento).*?([0-9]{8}[A-Z]|[XYZ][0-9]{7}[A-Z])/gi
    };
    
    const extracted = {};
    
    for (const [field, pattern] of Object.entries(patterns)) {
        const match = pattern.exec(text);
        extracted[field] = match ? match[1].trim() : null;
        pattern.lastIndex = 0; // Reset regex
    }
    
    return extracted;
}
```

#### Opci√≥n B: NER con Transformers.js (Para casos m√°s complejos)
```javascript
import { pipeline } from '@xenova/transformers';

// Configurar modelo de reconocimiento de entidades nombradas
const nerPipeline = await pipeline('token-classification', 'Davlan/bert-base-multilingual-cased-ner-hrl');

async function extractWithNER(text) {
    try {
        const entities = await nerPipeline(text);
        
        const extracted = {
            nombres: [],
            fechas: [],
            organizaciones: []
        };
        
        entities.forEach(entity => {
            if (entity.entity.includes('PER')) {
                extracted.nombres.push(entity.word);
            } else if (entity.entity.includes('DATE')) {
                extracted.fechas.push(entity.word);
            } else if (entity.entity.includes('ORG')) {
                extracted.organizaciones.push(entity.word);
            }
        });
        
        return extracted;
    } catch (error) {
        console.error('Error en NER:', error);
        return null;
    }
}
```

### 3. **Integraci√≥n Completa**

```javascript
class PrivateSpeechProcessor {
    constructor() {
        this.transcriber = null;
        this.isInitialized = false;
    }
    
    async initialize() {
        if (!this.isInitialized) {
            console.log('Cargando modelo de transcripci√≥n...');
            this.transcriber = await pipeline('automatic-speech-recognition', 'Xenova/whisper-base', {
                quantized: true,
                device: 'webgpu'
            });
            this.isInitialized = true;
            console.log('Modelo cargado exitosamente');
        }
    }
    
    async processAudio(audioBlob) {
        await this.initialize();
        
        // 1. Transcribir audio localmente
        const transcript = await this.transcriber(audioBlob);
        console.log('Transcripci√≥n:', transcript.text);
        
        // 2. Extraer datos localmente
        const extractedData = extractPersonalData(transcript.text);
        console.log('Datos extra√≠dos:', extractedData);
        
        // 3. Enviar solo datos procesados a Google Sheets
        await this.sendToGoogleSheets(extractedData);
        
        return extractedData;
    }
    
    async sendToGoogleSheets(data) {
        // Implementar env√≠o a Google Sheets
        // Solo se env√≠an datos ya procesados, no el audio ni texto original
        try {
            const response = await fetch('TU_WEBHOOK_GOOGLE_SHEETS', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(data)
            });
            return response.ok;
        } catch (error) {
            console.error('Error enviando a Google Sheets:', error);
            return false;
        }
    }
}
```

---

## Consideraciones de Rendimiento

### **Tama√±os de Modelo Whisper**
| Modelo | Tama√±o | Precisi√≥n | Velocidad | Recomendaci√≥n |
|--------|--------|-----------|-----------|---------------|
| tiny   | 39MB   | B√°sica    | Muy r√°pida | Prototipado |
| base   | 74MB   | Buena     | R√°pida    | **Recomendada** |
| small  | 244MB  | Muy buena | Media     | Calidad alta |
| medium | 769MB  | Excelente | Lenta     | Solo si es cr√≠tico |

### **Optimizaciones**
```javascript
// Precarga del modelo en el inicio de la app
window.addEventListener('load', async () => {
    const processor = new PrivateSpeechProcessor();
    await processor.initialize(); // Carga el modelo una sola vez
});

// Usar Web Workers para no bloquear UI
const worker = new Worker('speech-worker.js');
worker.postMessage({ audio: audioBlob });
```

---

## Plan de Migraci√≥n

### **Fase 1: Preparaci√≥n**
1. ‚úÖ Configurar Transformers.js en el proyecto
2. ‚úÖ Implementar funci√≥n de transcripci√≥n local
3. ‚úÖ Crear patrones de extracci√≥n espec√≠ficos para tu dominio
4. ‚úÖ Configurar tests con audios de ejemplo

### **Fase 2: Implementaci√≥n**
1. ‚úÖ Integrar transcripci√≥n local en paralelo con API actual
2. ‚úÖ Comparar resultados y ajustar patrones
3. ‚úÖ Implementar fallback a API si falla local
4. ‚úÖ Optimizar rendimiento y UX

### **Fase 3: Migraci√≥n Completa**
1. ‚úÖ Desactivar llamadas a OpenAI API
2. ‚úÖ Monitorear m√©tricas de precisi√≥n
3. ‚úÖ Ajustar modelos basado en feedback real
4. ‚úÖ Documentar para mantenimiento

---

## C√≥digo de Ejemplo Completo

### **HTML Base**
```html
<!DOCTYPE html>
<html>
<head>
    <title>Transcripci√≥n Privada</title>
</head>
<body>
    <button id="recordBtn">üé§ Grabar</button>
    <button id="stopBtn" disabled>‚èπÔ∏è Parar</button>
    <div id="status">Listo</div>
    <div id="results"></div>
    
    <script type="module" src="app.js"></script>
</body>
</html>
```

### **JavaScript Principal (app.js)**
```javascript
import { PrivateSpeechProcessor } from './speech-processor.js';

const processor = new PrivateSpeechProcessor();
let mediaRecorder;
let audioChunks = [];

// Configurar interfaz
document.getElementById('recordBtn').onclick = startRecording;
document.getElementById('stopBtn').onclick = stopRecording;

async function startRecording() {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    mediaRecorder = new MediaRecorder(stream);
    
    mediaRecorder.ondataavailable = (event) => {
        audioChunks.push(event.data);
    };
    
    mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
        audioChunks = [];
        
        document.getElementById('status').textContent = 'Procesando...';
        const results = await processor.processAudio(audioBlob);
        
        document.getElementById('results').innerHTML = `
            <h3>Datos Extra√≠dos:</h3>
            <pre>${JSON.stringify(results, null, 2)}</pre>
        `;
        document.getElementById('status').textContent = 'Completado';
    };
    
    mediaRecorder.start();
    document.getElementById('recordBtn').disabled = true;
    document.getElementById('stopBtn').disabled = false;
    document.getElementById('status').textContent = 'Grabando...';
}

function stopRecording() {
    mediaRecorder.stop();
    document.getElementById('recordBtn').disabled = false;
    document.getElementById('stopBtn').disabled = true;
}
```

---

## Ventajas de la Nueva Arquitectura

### üîí **Privacidad Total**
- Audio nunca sale del dispositivo del usuario
- Datos personales se procesan localmente
- Solo datos estructurados van a Google Sheets

### üí∞ **Cero Costos de API**
- Elimina gastos de OpenAI Whisper API (~$0.006/minuto)
- Elimina gastos de OpenAI Text Processing API
- Solo mantiene Google Sheets (gratis hasta l√≠mites)

### ‚ö° **Mejor Rendimiento**
- Sin latencia de red para procesamiento
- Funciona offline una vez cargado
- Control total sobre optimizaciones

### üõ°Ô∏è **Cumplimiento Regulatorio**
- GDPR compliant by design
- Sin transferencia de datos personales
- Auditable y transparente

---

## Preguntas para Claude Code

1. **¬øQu√© campos espec√≠ficos extraes actualmente?** (para crear patrones m√°s precisos)
2. **¬øEn qu√© framework est√° construida tu app?** (React, Vue, vanilla JS)
3. **¬øQu√© navegadores necesitas soportar?** (para compatibilidad de WebAssembly)
4. **¬øCu√°l es el volumen de uso esperado?** (para optimizaciones de performance)
5. **¬øHay alg√∫n formato espec√≠fico requerido para Google Sheets?**

---

**Nota**: Esta implementaci√≥n garantiza que los datos sensibles nunca salgan del dispositivo del usuario, cumpliendo con regulaciones de privacidad mientras mantiene la funcionalidad original.